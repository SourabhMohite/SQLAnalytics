{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are a few:\n",
      "\n",
      "1. Why don't scientists trust atoms?\n",
      "Because they make up everything!\n",
      "2. Why don't eggs tell time?\n",
      "Because they're always cracking under pressure!\n",
      "3. What did the ocean say to the beach?\n",
      "Nothing, it just waved!\n",
      "4. Why don't lobsters share?\n",
      "Because they're shellfish! \n",
      "5. What do you call a fake noodle?\n",
      "An impasta!\n",
      "6. Why did the scarecrow win an award?\n",
      "Because he was outstanding in his field!\n",
      "7. What do you call a group of cows playing instruments?\n",
      "A moo-sical band!\n",
      "8. Why did the bicycle fall over?\n",
      "Because it was two-tired!\n",
      "9. What do you call a can opener that doesn't work?\n",
      "A can't opener! \n",
      "10. Why did the mushroom go to the party?\n",
      "Because he was a fun-gi!\n",
      "\n",
      "Hope these jokes made you smile! Do you want more?\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(\n",
    "    model=\"llama3\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"tell me some jokes\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "print(response[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's one:\n",
      "\n",
      "Elephants have a unique way of showing empathy and mourning for their loved ones. When an elephant in the herd dies, the other elephants will often visit the body and touch it with their trunks to say goodbye. They'll also hold ceremonies around the body, where they'll stay for hours or even days, sometimes touching each other's trunks as a way of comforting one another.\n",
      "\n",
      "But here's the amazing part: Elephants have also been known to remember and mourn the death of their loved ones years after they've passed away! In one famous study, an elephant named Tarra remembered her best friend, a matriarchal figure named Ruby, even 6 years after she had died. Tarra would often visit Ruby's grave and leave gifts for her, as if hoping to revive their friendship.\n",
      "\n",
      "This level of empathy, self-awareness, and long-term memory is truly remarkable in the animal kingdom!"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from ollama import AsyncClient\n",
    "\n",
    "async def chat():\n",
    "    \"\"\"\n",
    "    Stream a chat from Llama using the AsyncClient.\n",
    "    \"\"\"\n",
    "    message = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Tell me an interesting fact about elephants\"\n",
    "    }\n",
    "    async for part in await AsyncClient().chat(\n",
    "        model=\"llama3\", messages=[message], stream=True\n",
    "    ):\n",
    "        print(part[\"message\"][\"content\"], end=\"\", flush=True)\n",
    "\n",
    "\n",
    "await chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sourabh.mohite\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\aiohttp\\http_writer.py:18: RuntimeWarning: coroutine 'chat' was never awaited\n",
      "  from .abc import AbstractStreamWriter\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "C:\\Users\\sourabh.mohite\\AppData\\Local\\Temp\\ipykernel_27088\\3896542766.py:6: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"llama3\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A classic!\\n\\n\"Genevieve\\'s Surprise: Gene Is Missing!\" is a popular children\\'s book written by Stuart J. Murphy and illustrated by George Ullych. The story was first published in 1997.\\n\\nThe plot revolves around Genevieve (nicknamed Gene), a young girl who loves to collect and categorize things. She has a special cabinet where she stores her treasures, each one labeled with a letter of the alphabet from A to Z.\\n\\nOne day, while Gene is busy at school, someone or something steals her prized possession, a yellow \"Y\" item (which remains a mystery throughout the story). Gene returns home from school to find her cabinet in disarray and her favorite treasure gone!\\n\\nDetermined to solve the mystery, Gene decides to investigate and ask her friends for help. Along the way, she learns about different shapes, colors, and textures while searching for clues.\\n\\nAs Gene searches high and low, she encounters various characters who can provide hints or mislead her on her quest. The story takes her through various settings, such as school, park, home, and even a bookstore.\\n\\nThe book is known for its engaging storyline, colorful illustrations, and creative use of alphabetical categorization. It has become a beloved read-aloud favorite among children and parents alike!\\n\\nWould you like to know more about the author or illustrator behind this delightful story?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "llm = Ollama(model=\"llama3\")\n",
    "\n",
    "\n",
    "qa_chain = (\n",
    "   \n",
    "    llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "question = \"What is the story of the 'Gen√© is Missing' book?\"\n",
    "qa_chain.invoke(question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
